# File: app/ai_service.py
"""
AI Service - Handles chat with AI providers (OpenAI/DeepSeek)
Streaming support with sentence-level chunking
âœ… Enhanced emoji/markdown removal for TTS
"""

import os
import logging
import time
import re
import unicodedata
from typing import List, Dict, Optional, AsyncGenerator
from openai import AsyncOpenAI


class AIService:
    """AI Chat Service with streaming support"""

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://api.openai.com/v1",
        model: str = "gpt-4o-mini",
        system_prompt: str = "You are a helpful AI assistant.",
        temperature: float = 0.7,
        max_tokens: int = 500,
        max_context: int = 10,
    ):
        """Initialize AI Service"""
        self.logger = logging.getLogger("AIService")

        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.system_prompt = system_prompt
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.max_context = max_context

        # Detect provider
        self.provider = "deepseek" if "deepseek" in base_url.lower() else "openai"

        # Conversation history
        self.conversation_history: List[Dict[str, str]] = []

        self.logger.info("ğŸ¤– Initializing AI Service...")
        self.logger.info(f"   Provider: {self.provider}")
        self.logger.info(f"   Model: {model}")
        self.logger.info(f"   Streaming: Enabled")
        self.logger.info(f"   Emoji removal: Enhanced")

        try:
            self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
            self.logger.info("âœ… AI Service initialized")
            self._test_service()
        except Exception as e:
            self.logger.error(f"âŒ Failed to initialize AI client: {e}")
            raise

    def _test_service(self):
        """Test AI service"""
        import asyncio

        async def test():
            # âœ… UNPACK 3 VALUES: original, cleaned, language
            original, cleaned, language = await self.chat("Hello")
            self.clear_history()

        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                asyncio.create_task(test())
            else:
                asyncio.run(test())
            self.logger.info("âœ… AI test successful")
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI test skipped: {e}")

    def clean_text_for_tts(self, text: str) -> str:
        """
        âœ¨ CLEAN TEXT FOR TTS - ENHANCED VERSION âœ¨
        
        Loáº¡i bá»:
        - Emoji (ğŸ˜Š ğŸ‰ ğŸ‘ âœ… âŒ etc) - Piper Ä‘á»c thÃ nh "máº·t cÆ°á»i, máº¯t cÆ°á»i" ráº¥t buá»“n cÆ°á»i!
        - Markdown (**bold**, `code`, ~~strike~~)
        - Special symbols (âœ¨ â­ etc)
        - Brackets with single chars ([x], [!])
        
        Giá»¯ láº¡i:
        - Vietnamese diacritics (Ã Ã¡áº£Ã£áº¡...)
        - Basic punctuation (. , ! ? ; : - ' " /)
        - Numbers and letters
        """
        if not text:
            return ""
        
        original_text = text
        cleaned = text
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: Remove ALL emoji (comprehensive Unicode ranges)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        emoji_pattern = re.compile(
            "["
            "\U0001F1E0-\U0001F1FF"  # ğŸ‡»ğŸ‡³ flags
            "\U0001F300-\U0001F5FF"  # ğŸŒŸ symbols & pictographs
            "\U0001F600-\U0001F64F"  # ğŸ˜ŠğŸ˜‚ğŸ¥° emoticons
            "\U0001F680-\U0001F6FF"  # ğŸš€ğŸ‰ transport & map
            "\U0001F700-\U0001F77F"  # âš—ï¸ alchemical
            "\U0001F780-\U0001F7FF"  # ğŸ”º geometric shapes
            "\U0001F800-\U0001F8FF"  # â¬†ï¸ arrows
            "\U0001F900-\U0001F9FF"  # ğŸ¤”ğŸ™ supplemental symbols
            "\U0001FA00-\U0001FA6F"  # â™Ÿï¸ chess symbols
            "\U0001FA70-\U0001FAFF"  # ğŸ«¡ extended pictographs
            "\U00002700-\U000027BF"  # âœ…âŒâœ¨ dingbats
            "\U000024C2-\U0001F251"  # ğŸ…°ï¸ enclosed chars
            "\U0001f926-\U0001f937"  # ğŸ¤¦ face gestures
            "\U00010000-\U0010ffff"  # supplementary planes
            "\u2600-\u26FF"          # â˜€ï¸â­ misc symbols
            "\u2700-\u27BF"          # âœ‚ï¸ dingbats
            "\uFE00-\uFE0F"          # variation selectors
            "\u203C-\u3299"          # â€¼ï¸ misc technical
            "\u200D"                 # zero width joiner
            "\u2300-\u23FF"          # âŒš misc technical
            "\u2B50-\u2BFF"          # â­ misc symbols
            "]+",
            flags=re.UNICODE
        )
        cleaned = emoji_pattern.sub('', cleaned)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: Fallback - Remove using Unicode categories
        # Catches emoji that regex might miss
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        def is_emoji_char(c):
            """Check if character is emoji-like"""
            cat = unicodedata.category(c)
            # So = Symbol Other, Cn = Not Assigned
            return cat in ['So', 'Cn']
        
        cleaned = ''.join(c for c in cleaned if not is_emoji_char(c))
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 3: Remove Markdown formatting
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # **bold** or *italic* â†’ plain text
        cleaned = re.sub(r'\*\*(.+?)\*\*', r'\1', cleaned)  # **text**
        cleaned = re.sub(r'\*(.+?)\*', r'\1', cleaned)      # *text*
        
        # __underline__ or _italic_ â†’ plain text
        cleaned = re.sub(r'__(.+?)__', r'\1', cleaned)      # __text__
        cleaned = re.sub(r'_(.+?)_', r'\1', cleaned)        # _text_
        
        # ~~strikethrough~~ â†’ plain text
        cleaned = re.sub(r'~~(.+?)~~', r'\1', cleaned)
        
        # `code` or ```code block``` â†’ plain text
        cleaned = re.sub(r'`{1,3}(.+?)`{1,3}', r'\1', cleaned)
        
        # [link](url) â†’ link (keep text, remove URL)
        cleaned = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', cleaned)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 4: Remove brackets with single chars [x], [!], etc
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        cleaned = re.sub(r'\[\w\]', '', cleaned)
        cleaned = re.sub(r'\[!\]', '', cleaned)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 5: Remove extra symbols
        # Keep: Letters, numbers, Vietnamese, basic punctuation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Vietnamese vowels with diacritics
        vietnamese_chars = (
            'Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­'
            'Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡'
            'Ã¬Ã­á»‰Ä©á»‹'
            'Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£'
            'Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±'
            'á»³Ã½á»·á»¹á»µ'
            'Ä‘Ä'
        )
        
        # Allowed chars: a-zA-Z0-9 + Vietnamese + basic punctuation
        allowed_pattern = rf'[^\w\s\.,!?;:\-\'\"/()\[\]{vietnamese_chars}]'
        cleaned = re.sub(allowed_pattern, '', cleaned)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 6: Normalize whitespace
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Multiple spaces â†’ single space
        cleaned = ' '.join(cleaned.split())
        
        # Remove space before punctuation
        cleaned = re.sub(r'\s+([.,!?;:])', r'\1', cleaned)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 7: Log what was removed (for debugging)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if original_text != cleaned:
            removed = set(original_text) - set(cleaned)
            # Filter out common chars (space, letters)
            removed_special = {
                c for c in removed 
                if not c.isalnum() and not c.isspace()
            }
            if removed_special:
                removed_str = ''.join(sorted(removed_special))
                self.logger.debug(
                    f"ğŸ§¹ Cleaned TTS text:\n"
                    f"   Before: {original_text[:60]}{'...' if len(original_text) > 60 else ''}\n"
                    f"   After:  {cleaned[:60]}{'...' if len(cleaned) > 60 else ''}\n"
                    f"   Removed: {removed_str}"
                )
        
        return cleaned.strip()

    def detect_language(self, text: str) -> str:
        """
        ğŸ” DETECT LANGUAGE - Vietnamese priority
        
        Vietnamese voice (Piper) cÃ³ thá»ƒ Ä‘á»c English OK,
        nhÆ°ng English voice khÃ´ng Ä‘á»c Ä‘Æ°á»£c Vietnamese.
        â†’ Æ¯u tiÃªn Vietnamese náº¿u cÃ³ báº¥t ká»³ kÃ½ tá»± Viá»‡t nÃ o.
        """
        # Vietnamese diacritics pattern
        vietnamese_pattern = r'[Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘Ä]'
        
        # Any Vietnamese char â†’ use Vietnamese voice
        if re.search(vietnamese_pattern, text):
            return "vi"
        
        # Pure English check
        ascii_letters = len(re.findall(r'[a-zA-Z]', text))
        total_chars = len(re.sub(r'[\s\d\W]', '', text))
        
        if total_chars > 0 and ascii_letters / total_chars > 0.7:
            return "en"
        
        # Default to Vietnamese (safe for mixed content)
        return "vi"

    async def chat_stream(
        self,
        user_message: str,
        conversation_logger=None,
        device_id: str = None,
        device_type: str = None,
    ) -> AsyncGenerator[tuple[str, str, str, bool], None]:
        """
        ğŸŒŠ STREAM CHAT RESPONSE - Sentence by sentence
        
        Yields progressive chunks for real-time TTS:
        
        Yields:
            tuple[
                original_text: str,    # For display (with emoji/markdown)
                cleaned_text: str,     # For TTS (emoji removed)
                language: str,         # "vi" or "en"
                is_last: bool          # True for final chunk
            ]
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ’¬ User: {user_message}")
            
            # Add to history
            self.conversation_history.append({"role": "user", "content": user_message})
            
            # Limit history to max_context
            if len(self.conversation_history) > self.max_context * 2:
                self.conversation_history = self.conversation_history[-(self.max_context * 2):]
            
            # Prepare messages
            messages = [
                {"role": "system", "content": self.system_prompt}
            ] + self.conversation_history
            
            request_start = time.time()
            self.logger.info(f"â±ï¸  Streaming from {self.provider.upper()}...")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # CREATE STREAMING REQUEST
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                stream=True,
            )
            
            full_response = ""
            current_sentence = ""
            first_token_time = None
            sentence_count = 0
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PROCESS STREAM TOKEN BY TOKEN
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    token = chunk.choices[0].delta.content
                    full_response += token
                    current_sentence += token
                    
                    # Log first token latency
                    if first_token_time is None:
                        first_token_time = time.time() - request_start
                        self.logger.info(f"âš¡ First token: {first_token_time:.2f}s")
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # DETECT SENTENCE BOUNDARY
                    # Match: . ! ? vÃ  cÃ¡c biáº¿n thá»ƒ
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    if re.search(r'[.!?ã€‚ï¼ï¼Ÿ]\s*$', current_sentence):
                        original = current_sentence.strip()
                        
                        if original:
                            sentence_count += 1
                            
                            # âœ¨ CLEAN FOR TTS (remove emoji)
                            cleaned = self.clean_text_for_tts(original)
                            
                            # Only yield if text remains after cleaning
                            if cleaned:
                                language = self.detect_language(cleaned)
                                
                                self.logger.info(
                                    f"ğŸ“¤ Sentence {sentence_count} ({language}): "
                                    f"'{original[:50]}{'...' if len(original) > 50 else ''}'"
                                )
                                
                                # âœ… YIELD CHUNK
                                yield (original, cleaned, language, False)
                            else:
                                self.logger.debug(
                                    f"â­ï¸  Skipped empty sentence after cleaning: '{original[:30]}...'"
                                )
                            
                            # Reset for next sentence
                            current_sentence = ""
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # HANDLE REMAINING TEXT (no ending punctuation)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if current_sentence.strip():
                original = current_sentence.strip()
                cleaned = self.clean_text_for_tts(original)
                
                if cleaned:
                    sentence_count += 1
                    language = self.detect_language(cleaned)
                    
                    self.logger.info(
                        f"ğŸ“¤ Final sentence {sentence_count} ({language}): "
                        f"'{original[:50]}{'...' if len(original) > 50 else ''}'"
                    )
                    
                    yield (original, cleaned, language, True)
                else:
                    # Send end marker
                    yield ("", "", "", True)
            else:
                # Send end marker
                yield ("", "", "", True)
            
            # Add AI response to history
            self.conversation_history.append({
                "role": "assistant",
                "content": full_response
            })
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # LOG PERFORMANCE METRICS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            request_time = time.time() - request_start
            total_time = time.time() - start_time
            
            self.logger.info(
                f"ğŸ¤– Complete: {len(full_response)} chars, "
                f"{sentence_count} sentences"
            )
            self.logger.info(
                f"â±ï¸  Timing: First token {first_token_time:.2f}s, "
                f"Total {request_time:.2f}s"
            )
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SAVE TO DATABASE
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if conversation_logger and device_id:
                try:
                    await conversation_logger.log_conversation(
                        device_id=device_id,
                        device_type=device_type or "unknown",
                        user_message=user_message,
                        ai_response=full_response,
                        model=self.model,
                        provider=self.provider,
                        response_time=request_time,
                    )
                except Exception as log_error:
                    self.logger.error(f"âŒ MySQL log error: {log_error}")
            
        except Exception as e:
            self.logger.error(f"âŒ Chat stream error: {e}", exc_info=True)
            # Yield error message
            yield (
                "Xin lá»—i, chá»‹ gáº·p lá»—i khi xá»­ lÃ½.", 
                "Xin lá»—i, chá»‹ gáº·p lá»—i khi xá»­ lÃ½.", 
                "vi", 
                True
            )

    async def chat(
        self,
        user_message: str,
        conversation_logger=None,
        device_id: str = None,
        device_type: str = None,
    ) -> tuple[str, str, str]:
        """
        ğŸ’¬ NON-STREAMING CHAT (backward compatible)
        
        Collects all streaming chunks and returns complete response.
        
        âœ¨ Returns BOTH original (display) and cleaned (TTS) text
        
        Returns:
            tuple[
                original_text: str,  # CÃ³ emoji/markdown - cho DISPLAY
                cleaned_text: str,   # KhÃ´ng emoji - cho TTS  
                language: str        # "vi" hoáº·c "en"
            ]
        """
        full_original = ""
        full_cleaned = ""
        language = "vi"
        
        async for original, cleaned, lang, is_last in self.chat_stream(
            user_message, conversation_logger, device_id, device_type
        ):
            if original:
                full_original += original + " "
            if cleaned:
                full_cleaned += cleaned + " "
            language = lang
        
        return (
            full_original.strip(),
            full_cleaned.strip(),
            language
        )


    def clear_history(self):
        """ğŸ—‘ï¸ Clear conversation history"""
        self.conversation_history = []
        self.logger.info("ğŸ—‘ï¸ Conversation history cleared")

    def get_history(self) -> List[Dict[str, str]]:
        """ğŸ“œ Get conversation history"""
        return self.conversation_history.copy()

    def get_context_size(self) -> int:
        """ğŸ“Š Get current context size"""
        return len(self.conversation_history)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TEST SUITE - Run with: python app/ai_service.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    import logging
    
    # Setup logging
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Mock AI service for testing cleaning only
    class MockAIService:
        def __init__(self):
            self.logger = logging.getLogger("TestClean")
        
        # Copy the cleaning methods
        clean_text_for_tts = AIService.clean_text_for_tts
        detect_language = AIService.detect_language
    
    service = MockAIService()
    
    # Test cases
    test_cases = [
        # Emoji tests
        ("Xin chÃ o ğŸ˜Š báº¡n nhÃ©!", "Piper sáº½ Ä‘á»c 'máº·t cÆ°á»i máº¯t cÆ°á»i' - pháº£i loáº¡i bá»!"),
        ("ChÃºc má»«ng ğŸ‰ğŸŠ nÄƒm má»›i! ğŸ†", "Multiple emoji"),
        ("TÃ´i Ä‘á»“ng Ã½ ğŸ‘âœ…", "Thumbs + checkmark"),
        ("Cáº£m Æ¡n báº¡n ğŸ™ğŸ’•", "Prayer hands + heart"),
        ("Wow ğŸ¤”ğŸ”¥ tuyá»‡t vá»i!", "Thinking + fire"),
        ("Hello âœ¨ world â­", "Sparkles + star"),
        
        # Markdown tests
        ("This is **bold** text", "Bold markdown"),
        ("This is *italic* text", "Italic markdown"),
        ("This is __underlined__ text", "Underline markdown"),
        ("This is ~~strikethrough~~ text", "Strikethrough markdown"),
        ("This is `code` text", "Inline code"),
        ("Check this [link](http://example.com)", "Link markdown"),
        
        # Mixed tests
        ("**Xin chÃ o** ğŸ˜Š `báº¡n` nhÃ©!", "Mixed Vietnamese + emoji + markdown"),
        ("[!] Warning: Please check ğŸ”¥", "Brackets + emoji"),
        
        # Vietnamese-only (should keep)
        ("Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ AI.", "Pure Vietnamese - keep all"),
        
        # English-only
        ("Hello, I am your AI assistant.", "Pure English"),
    ]
    
    print("\n" + "="*70)
    print("ğŸ§ª TESTING EMOJI/MARKDOWN REMOVAL FOR TTS")
    print("="*70)
    
    for i, (text, description) in enumerate(test_cases, 1):
        cleaned = service.clean_text_for_tts(text)
        language = service.detect_language(cleaned)
        
        print(f"\n{'â”€'*70}")
        print(f"Test {i}: {description}")
        print(f"{'â”€'*70}")
        print(f"ğŸ“ Original:  {text}")
        print(f"âœ¨ Cleaned:   {cleaned}")
        print(f"ğŸŒ Language:  {language}")
        
        # Show what was removed
        if text != cleaned:
            removed_chars = sorted(set(text) - set(cleaned))
            print(f"ğŸ—‘ï¸  Removed:   {''.join(c for c in removed_chars if not c.isalnum() and not c.isspace())}")
    
    print("\n" + "="*70)
    print("âœ… Testing complete!")
    print("="*70)
